{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spotify_data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1159764 entries, 0 to 1159763\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   Unnamed: 0        1159764 non-null  int64  \n",
      " 1   artist_name       1159749 non-null  object \n",
      " 2   track_name        1159763 non-null  object \n",
      " 3   track_id          1159764 non-null  object \n",
      " 4   popularity        1159764 non-null  int64  \n",
      " 5   year              1159764 non-null  int64  \n",
      " 6   genre             1159764 non-null  object \n",
      " 7   danceability      1159764 non-null  float64\n",
      " 8   energy            1159764 non-null  float64\n",
      " 9   key               1159764 non-null  int64  \n",
      " 10  loudness          1159764 non-null  float64\n",
      " 11  mode              1159764 non-null  int64  \n",
      " 12  speechiness       1159764 non-null  float64\n",
      " 13  acousticness      1159764 non-null  float64\n",
      " 14  instrumentalness  1159764 non-null  float64\n",
      " 15  liveness          1159764 non-null  float64\n",
      " 16  valence           1159764 non-null  float64\n",
      " 17  tempo             1159764 non-null  float64\n",
      " 18  duration_ms       1159764 non-null  int64  \n",
      " 19  time_signature    1159764 non-null  int64  \n",
      "dtypes: float64(9), int64(7), object(4)\n",
      "memory usage: 177.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaramos funciones útiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_outliers(df_aux, columns: list)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Función que elimina los valores atípicos de un dataframe en base a los cuartiles.\n",
    "    \n",
    "    Args: df_aux: DataFrame a limpiar.\n",
    "        columns: Lista de columnas a limpiar.\n",
    "    Returns: DataFrame sin valores atípicos\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        Q1 = df_aux[column].quantile(0.25)\n",
    "        Q3 = df_aux[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        df_aux = df_aux[(df_aux[column] >= Q1-1.5*IQR) & (df_aux[column] <= Q3 + 1.5*IQR)]\n",
    "    return df_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df:pd.DataFrame, columns:list[str]):\n",
    "    # restar la media y dividir entre la desviacion tipica\n",
    "    for column in columns:\n",
    "        df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para un correcto funcionamiento, preprocesamos los datos de cara al machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_outliers(df, ['loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'danceability', 'energy']) # Eliminamos los outliers\n",
    "df[\"loudness\"] = StandardScaler().fit_transform(df[[\"loudness\"]]) # Escalamos la columna loudness para que no haya tanto rango entre las variables\n",
    "df = normalize_data(df, [\"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\", \"valence\"]) # Normalizamos las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = df[df[\"popularity\"] >= 50] # Aplicamos un filtro para quedarnos sólo con las canciones populares, obteniendo un mejor aprendice para el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### División de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_aux.drop(columns={\"Unnamed: 0\", \"popularity\", \"artist_name\", \"track_name\", \"track_id\", \"genre\", \"duration_ms\", \"time_signature\", \"key\", \"mode\", \"tempo\"}, axis=1), df_aux['popularity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamos varios modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 100\n",
    "max_iter = 500\n",
    "\n",
    "model = HuberRegressor(epsilon=epsilon, max_iter=max_iter)\n",
    "model.fit(X_train, y_train) \n",
    "mse_SVR = mse(y_test,model.predict(X_test))\n",
    "print(mse_SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.631559365748736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.3s\n"
     ]
    }
   ],
   "source": [
    "#Librerías\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#Inicializamos modelo y parámetros\n",
    "n_estimators = 200 #Estimadores del modelo\n",
    "criterion = 'squared_error' #Forma de calcular el error\n",
    "max_depth = None #Límite de profundidad de los árboles\n",
    "min_samples_split = 2 #Criterio de parada de profundidad\n",
    "verbose = 1 #Información devuelta por el método\n",
    "#Instanciamos el modelo\n",
    "model = RandomForestRegressor(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, verbose=verbose)\n",
    "#Entrenamos modelo y elaboramos predicciones\n",
    "model.fit(X_train, y_train)\n",
    "mse_RF = mse(y_test,model.predict(X_test))\n",
    "print(mse_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.79619859919413\n"
     ]
    }
   ],
   "source": [
    "#Librerías\n",
    "import xgboost as xgb\n",
    "#Inicializamos modelo y parámetros\n",
    "params = {\"booster\":\"gbtree\", \"max_depth\": 2, \"eta\": 0.3, \"objective\": \"reg:squarederror\", \"nthread\":2}\n",
    "num_boost_round = 10\n",
    "train_data = xgb.DMatrix(X_train, label=y_train)\n",
    "test_data = xgb.DMatrix(X_test, label=y_test)\n",
    "#Instanciamos el modelo, entrenamos y elaboramos predicciones\n",
    "model = xgb.train(params = params, dtrain = train_data, num_boost_round=num_boost_round)\n",
    "mse_XGB = mse(y_test,model.predict(test_data))\n",
    "print(mse_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.059615593146546\n"
     ]
    }
   ],
   "source": [
    "#Librerías\n",
    "from sklearn import svm\n",
    "#Inicializamos modelo y parámetros\n",
    "C = 1 #Parámetro regularizador\n",
    "kernel = 'rbf' #Núcleo transformador\n",
    "#Instanciamos el modelo\n",
    "model = svm.SVR(C = C, kernel = kernel)\n",
    "#Entrenamos modelo y elaboramos predicciones\n",
    "model.fit(X_train, y_train)\n",
    "mse_SVR = mse(y_test,model.predict(X_test))\n",
    "print(mse_SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Modelo')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse = [mse_SVR, mse_RF, mse_XGB]\n",
    "plt.scatter(['SVR', 'RF', 'XGB'], mse)\n",
    "plt.ylabel('mse')\n",
    "plt.xlabel('Modelo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusión:\n",
    "##### Pese a que con el filtro de popularidad > 50 hemos conseguido bajar el MSE de 250 a 47 aproximadamente, no parece que sea lo suficientemente preciso como para sernos útil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos dos funciones para categorizar la variable objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### La primera la categoriza en tres intervalos diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity1(x):\n",
    "    if 25 > x >= 0 :\n",
    "        return \"Baja popularidad\"\n",
    "    elif 55 > x >= 25:\n",
    "        return \"Popularidad media\"\n",
    "    else:\n",
    "        return \"Alta popularidad\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### La segunda la categoriza en sólo dos intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity2(x):\n",
    "    if 50 > x >= 0 :\n",
    "        return \"Baja popularidad\"\n",
    "    else:\n",
    "        return \"Alta popularidad\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Al hacer pruebas, observamos que al categorizarla en dos intervalos incrementa considerablemente su precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"popularity_target\"] = df[\"popularity\"].apply(lambda x: popularity2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para aumentar aún más su precisión, cogemos una muestra con la misma cantidad de valores por categoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "popularity_target\n",
       "Baja popularidad    849109\n",
       "Alta popularidad     41044\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"popularity_target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = df[df[\"popularity_target\"] == \"Baja popularidad\"].sample(41000, random_state=42)\n",
    "df_aux2 = df[df[\"popularity_target\"] == \"Alta popularidad\"].sample(41000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = pd.concat([df_aux, df_aux2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparamos los datos dropeando columnas y redondeando las cifras para una mejor gestión de predicciones en la app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = df_aux.drop(columns={\"Unnamed: 0\", \"popularity\", \"artist_name\", \"track_name\", \"track_id\", \"genre\", \"duration_ms\", \"time_signature\", \"key\", \"mode\", \"liveness\", \"year\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_aux.columns:\n",
    "    if i != \"popularity_target\":\n",
    "        df_aux[i] = df_aux[i].map(lambda x: np.round(x, 2)) # Aplicamos una función sencilla, al no poder aplicar un redondeo a un string recorremos cada columna del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>popularity_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>751506</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-3.81</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>153.10</td>\n",
       "      <td>Baja popularidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143104</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-10.24</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.29</td>\n",
       "      <td>83.95</td>\n",
       "      <td>Baja popularidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735799</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-4.88</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>118.80</td>\n",
       "      <td>Baja popularidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144395</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-3.76</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.53</td>\n",
       "      <td>94.91</td>\n",
       "      <td>Baja popularidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131657</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-7.45</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>72.63</td>\n",
       "      <td>Baja popularidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74568</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-6.48</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>126.08</td>\n",
       "      <td>Alta popularidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542346</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-10.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>124.01</td>\n",
       "      <td>Alta popularidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837948</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-6.60</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>132.02</td>\n",
       "      <td>Alta popularidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390200</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-5.70</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>153.01</td>\n",
       "      <td>Alta popularidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150744</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>135.84</td>\n",
       "      <td>Alta popularidad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         danceability  energy  loudness  speechiness  acousticness  \\\n",
       "751506           0.62    0.90     -3.81         0.04          0.05   \n",
       "1143104          0.58    0.50    -10.24         0.03          0.61   \n",
       "735799           0.42    0.75     -4.88         0.04          0.00   \n",
       "1144395          0.55    0.94     -3.76         0.12          0.00   \n",
       "131657           0.32    0.58     -7.45         0.04          0.11   \n",
       "...               ...     ...       ...          ...           ...   \n",
       "74568            0.74    0.72     -6.48         0.06          0.72   \n",
       "542346           0.68    0.71    -10.76         0.04          0.02   \n",
       "837948           0.76    0.66     -6.60         0.04          0.03   \n",
       "390200           0.65    0.80     -5.70         0.16          0.45   \n",
       "1150744          0.70    0.52     -4.86         0.10          0.03   \n",
       "\n",
       "         instrumentalness  valence   tempo popularity_target  \n",
       "751506               0.00     0.75  153.10  Baja popularidad  \n",
       "1143104              0.42     0.29   83.95  Baja popularidad  \n",
       "735799               0.45     0.07  118.80  Baja popularidad  \n",
       "1144395              0.01     0.53   94.91  Baja popularidad  \n",
       "131657               0.00     0.50   72.63  Baja popularidad  \n",
       "...                   ...      ...     ...               ...  \n",
       "74568                0.00     0.97  126.08  Alta popularidad  \n",
       "542346               0.03     0.05  124.01  Alta popularidad  \n",
       "837948               0.01     0.55  132.02  Alta popularidad  \n",
       "390200               0.00     0.32  153.01  Alta popularidad  \n",
       "1150744              0.00     0.77  135.84  Alta popularidad  \n",
       "\n",
       "[82000 rows x 9 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividimos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_aux.drop(columns={\"popularity_target\"}, axis=1), df_aux['popularity_target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITROPC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Alta popularidad       0.66      0.75      0.70      8205\n",
      "Baja popularidad       0.71      0.62      0.66      8195\n",
      "\n",
      "        accuracy                           0.68     16400\n",
      "       macro avg       0.68      0.68      0.68     16400\n",
      "    weighted avg       0.68      0.68      0.68     16400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create an instance of Logistic Regression Classifier and fit the data.\n",
    "logreg = LogisticRegression(max_iter =100)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Alta popularidad       0.62      0.72      0.67      8205\n",
      "Baja popularidad       0.67      0.55      0.60      8195\n",
      "\n",
      "        accuracy                           0.64     16400\n",
      "       macro avg       0.64      0.64      0.63     16400\n",
      "    weighted avg       0.64      0.64      0.63     16400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Parámetros\n",
    "weights = 'distance'\n",
    "p = 2\n",
    "n_neighbours = 10\n",
    "#Modelo\n",
    "clf = KNeighborsClassifier(n_neighbors = n_neighbours, weights = weights, p = p)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Alta popularidad       0.60      0.84      0.70      8205\n",
      "Baja popularidad       0.74      0.45      0.56      8195\n",
      "\n",
      "        accuracy                           0.65     16400\n",
      "       macro avg       0.67      0.65      0.63     16400\n",
      "    weighted avg       0.67      0.65      0.63     16400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Tratamos datos como pd.DataFrame\n",
    "#Modelo\n",
    "nbmodelo = GaussianNB()\n",
    "\n",
    "nbmodelo.fit(X_train, y_train)\n",
    "y_pred = nbmodelo.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Alta popularidad       0.68      0.72      0.70      8205\n",
      "Baja popularidad       0.70      0.66      0.68      8195\n",
      "\n",
      "        accuracy                           0.69     16400\n",
      "       macro avg       0.69      0.69      0.69     16400\n",
      "    weighted avg       0.69      0.69      0.69     16400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(X_train, y_train)\n",
    "y_preds = RFC.predict(X_test)\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Alta popularidad       0.67      0.75      0.71      8205\n",
      "Baja popularidad       0.71      0.62      0.67      8195\n",
      "\n",
      "        accuracy                           0.69     16400\n",
      "       macro avg       0.69      0.69      0.69     16400\n",
      "    weighted avg       0.69      0.69      0.69     16400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(random_state=357, validation_fraction=0.1,n_iter_no_change=5, tol=0.01)\n",
    "clf.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test) #comentario prueba\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Los modelos de clasificación hacen un mejor trabajo que los de regresión, llegando hasta un 0.69 de accuracy. Los datos ya están preparados para llevarlos a azure y entrenar los modelos en la nube, pudiendo ver así mucho más rápidamente qué modelo es el más óptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_aux.to_csv('spotify_data_machine_learning.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
