{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spotify_data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1159764 entries, 0 to 1159763\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   Unnamed: 0        1159764 non-null  int64  \n",
      " 1   artist_name       1159749 non-null  object \n",
      " 2   track_name        1159763 non-null  object \n",
      " 3   track_id          1159764 non-null  object \n",
      " 4   popularity        1159764 non-null  int64  \n",
      " 5   year              1159764 non-null  int64  \n",
      " 6   genre             1159764 non-null  object \n",
      " 7   danceability      1159764 non-null  float64\n",
      " 8   energy            1159764 non-null  float64\n",
      " 9   key               1159764 non-null  int64  \n",
      " 10  loudness          1159764 non-null  float64\n",
      " 11  mode              1159764 non-null  int64  \n",
      " 12  speechiness       1159764 non-null  float64\n",
      " 13  acousticness      1159764 non-null  float64\n",
      " 14  instrumentalness  1159764 non-null  float64\n",
      " 15  liveness          1159764 non-null  float64\n",
      " 16  valence           1159764 non-null  float64\n",
      " 17  tempo             1159764 non-null  float64\n",
      " 18  duration_ms       1159764 non-null  int64  \n",
      " 19  time_signature    1159764 non-null  int64  \n",
      "dtypes: float64(9), int64(7), object(4)\n",
      "memory usage: 177.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_outliers(df_aux, columns: list)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Función que elimina los valores atípicos de un dataframe en base a los cuartiles.\n",
    "    \n",
    "    Args: df_aux: DataFrame a limpiar.\n",
    "        columns: Lista de columnas a limpiar.\n",
    "    Returns: DataFrame sin valores atípicos\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        Q1 = df_aux[column].quantile(0.25)\n",
    "        Q3 = df_aux[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        df_aux = df_aux[(df_aux[column] >= Q1-1.5*IQR) & (df_aux[column] <= Q3 + 1.5*IQR)]\n",
    "    return df_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_outliers(df, ['loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'danceability', 'energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df:pd.DataFrame, columns:list[str]):\n",
    "    # restar la media y dividir entre la desviacion tipica\n",
    "    for column in columns:\n",
    "        df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"loudness\"] = StandardScaler().fit_transform(df[[\"loudness\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalize_data(df, [\"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\", \"valence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(frac=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = df[df[\"popularity\"] >= 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_aux.drop(columns={\"Unnamed: 0\", \"popularity\", \"artist_name\", \"track_name\", \"track_id\", \"genre\", \"duration_ms\", \"time_signature\", \"key\", \"mode\", \"tempo\"}, axis=1), df_aux['popularity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>838735</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.653244</td>\n",
       "      <td>0.092183</td>\n",
       "      <td>0.483433</td>\n",
       "      <td>-0.789793</td>\n",
       "      <td>-0.778212</td>\n",
       "      <td>-0.680122</td>\n",
       "      <td>-0.761285</td>\n",
       "      <td>1.381445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40643</th>\n",
       "      <td>2012</td>\n",
       "      <td>1.634841</td>\n",
       "      <td>-0.064693</td>\n",
       "      <td>1.003894</td>\n",
       "      <td>-0.101393</td>\n",
       "      <td>0.618427</td>\n",
       "      <td>-0.333984</td>\n",
       "      <td>-0.078991</td>\n",
       "      <td>1.848226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43793</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.601581</td>\n",
       "      <td>0.913717</td>\n",
       "      <td>0.866902</td>\n",
       "      <td>-0.655173</td>\n",
       "      <td>-0.803780</td>\n",
       "      <td>-0.680152</td>\n",
       "      <td>-0.249564</td>\n",
       "      <td>1.460497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542085</th>\n",
       "      <td>2022</td>\n",
       "      <td>-0.781839</td>\n",
       "      <td>0.315112</td>\n",
       "      <td>0.860700</td>\n",
       "      <td>-0.300264</td>\n",
       "      <td>-0.846104</td>\n",
       "      <td>-0.680143</td>\n",
       "      <td>2.174375</td>\n",
       "      <td>-1.155738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232777</th>\n",
       "      <td>2016</td>\n",
       "      <td>-1.516601</td>\n",
       "      <td>-1.790326</td>\n",
       "      <td>-1.810908</td>\n",
       "      <td>-0.792853</td>\n",
       "      <td>2.068309</td>\n",
       "      <td>0.468114</td>\n",
       "      <td>-0.572756</td>\n",
       "      <td>-1.193382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801565</th>\n",
       "      <td>2004</td>\n",
       "      <td>1.164133</td>\n",
       "      <td>-1.418778</td>\n",
       "      <td>-0.218515</td>\n",
       "      <td>-0.373693</td>\n",
       "      <td>0.425912</td>\n",
       "      <td>-0.680149</td>\n",
       "      <td>-0.411160</td>\n",
       "      <td>-0.338871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057606</th>\n",
       "      <td>2009</td>\n",
       "      <td>-0.483342</td>\n",
       "      <td>0.459603</td>\n",
       "      <td>0.375835</td>\n",
       "      <td>-0.309443</td>\n",
       "      <td>-0.667215</td>\n",
       "      <td>0.133203</td>\n",
       "      <td>-0.581734</td>\n",
       "      <td>-1.432043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119771</th>\n",
       "      <td>2014</td>\n",
       "      <td>-0.942568</td>\n",
       "      <td>-1.030717</td>\n",
       "      <td>-0.266246</td>\n",
       "      <td>-0.083035</td>\n",
       "      <td>-0.365206</td>\n",
       "      <td>-0.680109</td>\n",
       "      <td>0.800809</td>\n",
       "      <td>-0.839531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272539</th>\n",
       "      <td>2017</td>\n",
       "      <td>-0.035596</td>\n",
       "      <td>0.447218</td>\n",
       "      <td>0.418443</td>\n",
       "      <td>-0.358395</td>\n",
       "      <td>-0.852293</td>\n",
       "      <td>-0.680129</td>\n",
       "      <td>-0.644576</td>\n",
       "      <td>-0.432980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264878</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.785272</td>\n",
       "      <td>0.149980</td>\n",
       "      <td>0.798946</td>\n",
       "      <td>-0.431825</td>\n",
       "      <td>-0.814609</td>\n",
       "      <td>-0.680135</td>\n",
       "      <td>1.958914</td>\n",
       "      <td>-0.327578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30783 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  danceability    energy  loudness  speechiness  acousticness  \\\n",
       "838735   2005      0.653244  0.092183  0.483433    -0.789793     -0.778212   \n",
       "40643    2012      1.634841 -0.064693  1.003894    -0.101393      0.618427   \n",
       "43793    2012      0.601581  0.913717  0.866902    -0.655173     -0.803780   \n",
       "542085   2022     -0.781839  0.315112  0.860700    -0.300264     -0.846104   \n",
       "232777   2016     -1.516601 -1.790326 -1.810908    -0.792853      2.068309   \n",
       "...       ...           ...       ...       ...          ...           ...   \n",
       "801565   2004      1.164133 -1.418778 -0.218515    -0.373693      0.425912   \n",
       "1057606  2009     -0.483342  0.459603  0.375835    -0.309443     -0.667215   \n",
       "119771   2014     -0.942568 -1.030717 -0.266246    -0.083035     -0.365206   \n",
       "272539   2017     -0.035596  0.447218  0.418443    -0.358395     -0.852293   \n",
       "264878   2017      0.785272  0.149980  0.798946    -0.431825     -0.814609   \n",
       "\n",
       "         instrumentalness  liveness   valence  \n",
       "838735          -0.680122 -0.761285  1.381445  \n",
       "40643           -0.333984 -0.078991  1.848226  \n",
       "43793           -0.680152 -0.249564  1.460497  \n",
       "542085          -0.680143  2.174375 -1.155738  \n",
       "232777           0.468114 -0.572756 -1.193382  \n",
       "...                   ...       ...       ...  \n",
       "801565          -0.680149 -0.411160 -0.338871  \n",
       "1057606          0.133203 -0.581734 -1.432043  \n",
       "119771          -0.680109  0.800809 -0.839531  \n",
       "272539          -0.680129 -0.644576 -0.432980  \n",
       "264878          -0.680135  1.958914 -0.327578  \n",
       "\n",
       "[30783 rows x 9 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 100\n",
    "max_iter = 500\n",
    "\n",
    "model = HuberRegressor(epsilon=epsilon, max_iter=max_iter)\n",
    "model.fit(X_train, y_train) \n",
    "mse_SVR = mse(y_test,model.predict(X_test))\n",
    "print(mse_SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.631559365748736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.3s\n"
     ]
    }
   ],
   "source": [
    "#Librerías\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#Inicializamos modelo y parámetros\n",
    "n_estimators = 200 #Estimadores del modelo\n",
    "criterion = 'squared_error' #Forma de calcular el error\n",
    "max_depth = None #Límite de profundidad de los árboles\n",
    "min_samples_split = 2 #Criterio de parada de profundidad\n",
    "verbose = 1 #Información devuelta por el método\n",
    "#Instanciamos el modelo\n",
    "model = RandomForestRegressor(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, verbose=verbose)\n",
    "#Entrenamos modelo y elaboramos predicciones\n",
    "model.fit(X_train, y_train)\n",
    "mse_RF = mse(y_test,model.predict(X_test))\n",
    "print(mse_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.79619859919413\n"
     ]
    }
   ],
   "source": [
    "#Librerías\n",
    "import xgboost as xgb\n",
    "#Inicializamos modelo y parámetros\n",
    "params = {\"booster\":\"gbtree\", \"max_depth\": 2, \"eta\": 0.3, \"objective\": \"reg:squarederror\", \"nthread\":2}\n",
    "num_boost_round = 10\n",
    "train_data = xgb.DMatrix(X_train, label=y_train)\n",
    "test_data = xgb.DMatrix(X_test, label=y_test)\n",
    "#Instanciamos el modelo, entrenamos y elaboramos predicciones\n",
    "model = xgb.train(params = params, dtrain = train_data, num_boost_round=num_boost_round)\n",
    "mse_XGB = mse(y_test,model.predict(test_data))\n",
    "print(mse_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.059615593146546\n"
     ]
    }
   ],
   "source": [
    "#Librerías\n",
    "from sklearn import svm\n",
    "#Inicializamos modelo y parámetros\n",
    "C = 1 #Parámetro regularizador\n",
    "kernel = 'rbf' #Núcleo transformador\n",
    "#Instanciamos el modelo\n",
    "model = svm.SVR(C = C, kernel = kernel)\n",
    "#Entrenamos modelo y elaboramos predicciones\n",
    "model.fit(X_train, y_train)\n",
    "mse_SVR = mse(y_test,model.predict(X_test))\n",
    "print(mse_SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Modelo')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse = [mse_SVR, mse_RF, mse_XGB]\n",
    "plt.scatter(['SVR', 'RF', 'XGB'], mse)\n",
    "plt.ylabel('mse')\n",
    "plt.xlabel('Modelo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity(x):\n",
    "    if 25 > x >= 0 :\n",
    "        return \"Baja popularidad\"\n",
    "    elif 50 > x >= 25:\n",
    "        return \"Popularidad media\"\n",
    "    else:\n",
    "        return \"Alta popularidad\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity(x):\n",
    "    if 50 > x >= 0 :\n",
    "        return \"Baja popularidad\"\n",
    "    else:\n",
    "        return \"Alta popularidad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"popularity_target\"] = df[\"popularity\"].apply(lambda x: popularity(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "popularity_target\n",
       "Baja popularidad    849109\n",
       "Alta popularidad     41044\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"popularity_target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(columns={\"Unnamed: 0\", \"popularity\", \"artist_name\", \"track_name\", \"track_id\", \"genre\", \"duration_ms\", \"time_signature\", \"key\", \"mode\", \"tempo\", \"popularity_target\"}, axis=1), df['popularity_target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITROPC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Alta popularidad       0.00      0.00      0.00     10325\n",
      "Baja popularidad       0.95      1.00      0.98    212214\n",
      "\n",
      "        accuracy                           0.95    222539\n",
      "       macro avg       0.48      0.50      0.49    222539\n",
      "    weighted avg       0.91      0.95      0.93    222539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create an instance of Logistic Regression Classifier and fit the data.\n",
    "logreg = LogisticRegression(max_iter =100)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Alta popularidad       0.30      0.03      0.05     10325\n",
      "Baja popularidad       0.95      1.00      0.98    212214\n",
      "\n",
      "        accuracy                           0.95    222539\n",
      "       macro avg       0.63      0.51      0.51    222539\n",
      "    weighted avg       0.92      0.95      0.93    222539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Parámetros\n",
    "weights = 'distance'\n",
    "p = 2\n",
    "n_neighbours = 10\n",
    "#Modelo\n",
    "clf = KNeighborsClassifier(n_neighbors = n_neighbours, weights = weights, p = p)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Alta popularidad       0.33      0.01      0.02     10325\n",
      "Baja popularidad       0.95      1.00      0.98    212214\n",
      "\n",
      "        accuracy                           0.95    222539\n",
      "       macro avg       0.64      0.51      0.50    222539\n",
      "    weighted avg       0.92      0.95      0.93    222539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Tratamos datos como pd.DataFrame\n",
    "#Modelo\n",
    "nbmodelo = GaussianNB()\n",
    "\n",
    "nbmodelo.fit(X_train, y_train)\n",
    "y_pred = nbmodelo.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Alta popularidad       0.45      0.01      0.03     10325\n",
      "Baja popularidad       0.95      1.00      0.98    212214\n",
      "\n",
      "        accuracy                           0.95    222539\n",
      "       macro avg       0.70      0.51      0.50    222539\n",
      "    weighted avg       0.93      0.95      0.93    222539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(X_train, y_train)\n",
    "y_preds = RFC.predict(X_test)\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Alta popularidad       0.00      0.00      0.00     10325\n",
      "Baja popularidad       0.95      1.00      0.98    212214\n",
      "\n",
      "        accuracy                           0.95    222539\n",
      "       macro avg       0.48      0.50      0.49    222539\n",
      "    weighted avg       0.91      0.95      0.93    222539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(random_state=357, validation_fraction=0.1,n_iter_no_change=5, tol=0.01)\n",
    "clf.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test) #comentario prueba\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
